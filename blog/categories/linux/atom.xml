<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | 桑弧蓬矢射四方]]></title>
  <link href="http://iphyer.github.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://iphyer.github.com/"/>
  <updated>2018-04-18T20:28:35-05:00</updated>
  <id>http://iphyer.github.com/</id>
  <author>
    <name><![CDATA[iphyer]]></name>
    <email><![CDATA[iphyer@163.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[如何确保文件完全删除]]></title>
    <link href="http://iphyer.github.com/blog/2017/05/13/shred/"/>
    <updated>2017-05-13T09:42:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2017/05/13/shred</id>
    <content type="html"><![CDATA[<h2 id="section">原因</h2>

<p>最近需要把实验室的一块硬盘给另外一个实验室存储数据，他们把他们的数据写进去再还给我们。</p>

<p>所以需要把这块硬盘完全删除，毕竟这块硬盘其实是实验室的FTP分享硬盘。当然也是最近又升级了，所以
这块硬盘就空下来作为交换数据用了。</p>

<!--more-->

<h2 id="section-1">如何实现数据的完全删除</h2>

<p>其实google一下就可以搜索导致这个方法，主要是参考这个帖子 <a href="https://askubuntu.com/questions/17640/how-can-i-securely-erase-a-hard-drive">Securely erasing a storage device</a></p>

<h3 id="section-2">原理</h3>

<p>一般的删除其实都是再文件系统级别删除和操作，本质上其实是一种对于文件表的操作，并没有完全删除硬盘上的数据(0,1,0,1的bit)。操作系统只是把这块文件原来占有的 Bits 区域标记为可以使用，如果不做特别操作，事实是短时间内，这块 Bits 上的数据是完好无损的。所以，如果你有一种特别的程序可以完全拷贝 Bits　数据，这样的话，你只要知道文件的数据格式是可以恢复数据的。</p>

<p>所以最好的方法办法很简单就是在删除数据后把这些内存再随机重复写一边，比如随机写入 0,1　覆盖原来的数据。</p>

<h3 id="section-3">操作</h3>

<p>先用<code>fdisk</code>找出可用硬盘</p>

<pre><code>
sudo fdisk -l

</code></pre>

<p>然后运行如下命令写入相应的硬盘，比如再我的电脑上是<code>/dev/sdc</code></p>

<pre><code>
sudo shred -v -n1 -z /dev/sdX

</code></pre>

<p>命令中的<code>-n1</code>是只做一边，当然比较保险是做3边,然后是<code>-v</code>是给出详细的进度信息。</p>

<p>最后这块硬盘再重新格式化即可使用。</p>

<p>进入信息:</p>

<p><img src="/images/shred/shred.png" alt="tu1" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PDF裁边总结]]></title>
    <link href="http://iphyer.github.com/blog/2016/04/03/pdfcaibian/"/>
    <updated>2016-04-03T08:39:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2016/04/03/pdfcaibian</id>
    <content type="html"><![CDATA[<p>今天打印文献，以前都是在Windows下用Briss打印因为打印机只支持Windows下的双面打印，虽然HP官网说是支持Linux但是谁用谁知道啊，特别坑。</p>

<p>今天是因为需要打印的文献比较多，所以我觉得每次都用Briss裁边比较麻烦。但是不裁边的话很多论文，特别是比如PR系列的，公式就会很小。所以还是要裁边的，所以我还是需要裁边的。</p>

<p>搜索了下还是有不少工具的，但是还是这个博客介绍的最靠谱<a href="https://linhan.blog.ustc.edu.cn/?p=196">Linux 下裁剪pdf文件白边的简单命令</a>。</p>

<p>总结下就是</p>

<p>```
pdfcrop input.pdf output.pdf </p>

<p>```</p>

<p>当然一般还是要留一点白边的.</p>

<p><code>
pdfcrop --margins 10 input.pdf output.pdf 
</code></p>

<p>虽然最后打印的文档会变大，但是对于我来说无所谓，本来这样的裁边文件就只是为了打印而不需要存储。</p>

<p>当然如果你需要存储在移动设备中使用可能还需要参照博客的介绍用重新打印减小体积。</p>

<p>给出一个Bash脚本方便批量操作:</p>

<p>```bash</p>

<h1 id="binbash">! /bin/bash</h1>

<p>count=0</p>

<p>for f in *.pdf; do
    let count++
    name=”output$count”
    pdfcrop –margins 10 $f $name.pdf 	
done</p>

<p>echo “Done”</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ssh服务器修复和免密码登录]]></title>
    <link href="http://iphyer.github.com/blog/2016/03/21/ssh/"/>
    <updated>2016-03-21T22:47:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2016/03/21/ssh</id>
    <content type="html"><![CDATA[<h1 id="section">起因</h1>

<p>周六的时候，科学院停电，所以把服务器给停止了。今天上午重新启动机器，结果很奇怪出了两个问题。</p>

<ol>
  <li>无法登录部分节点</li>
  <li>修复之后发现每次都要 ssh 输入密码(当然这个是我在前一步排查的时候删除.ssh文件夹导致的)</li>
</ol>

<p>这里记录下怎么修复故障的。</p>

<!--more-->

<h1 id="section-1">修复不能登录节点问题</h1>

<p>重启机器还是挺简单的，但是需要注意的是顺序问题，先启动home node 然后是其他节点。</p>

<p>但是我没有注意启动home节点的时间问题。事实上，home节点的启动不是机器启动就OK的，而是需要等home节点彻底启动所有的服务，比如 sshd, ftp，PBS这些服务。今天启动的时候出现的问题就是，部分节点早于home节点的所有服务就位启动所以出现了非常严重的故障。机器找不到用户目录也就没办法验证用户的个人设置。</p>

<p>我排查了好久但是始终没有朝这个方向思考问题，所以基本上都没有起到好的效果。很多措施其实没必要。甚至为了确定错误，我在home节点删除了自己的.ssh文件夹。结果导致了下面的第二个问题。当然好在都做到了每次只改动一处地方同时没有效果就回滚，所以也没出大问题。</p>

<h1 id="ssh">ssh公钥登录</h1>

<p>其实不能说是免密码登录，你在第一次登录进账户的时候还是需要密码的。但是再用该受信任用户身份访问其他节点的时候可以让你不用输入密码。也就是一次验证，处处通行。真正的术语叫做公钥登录。</p>

<blockquote>
  <p>所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个。</p>
</blockquote>

<p>具体的原理相对来说就比较复杂了。参见阮一峰的这篇博客<a href="http://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html">SSH原理与运用(一):远程登录</a>。</p>

<p>最后的解决方案很简单就是生成本用户的秘钥，在把公钥存成authorized_keys文件。</p>

<p>简单来说，我们使用如下的命令：</p>

<p><code>bash
ssh user@host 'mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub
</code></p>

<p>过程是</p>

<ol>
  <li><code>ssh user@host</code>，表示登录远程主机,当然远程用户名和本地一致的时候可以省略，直接使用<code>ssh host</code>。</li>
  <li><code>mkdir -p .ssh</code>的作用是，如果用户主目录中的.ssh目录不存在，就创建一个。</li>
  <li><code>'cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub</code>的作用是将本地的公钥文件~/.ssh/id_rsa.pub，重定向追加到远程文件authorized_keys的末尾。</li>
</ol>

<p>写入authorized_keys文件后，公钥登录的设置就完成了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux下批量Kill多个进程的方法]]></title>
    <link href="http://iphyer.github.com/blog/2015/06/22/kill/"/>
    <updated>2015-06-22T20:12:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2015/06/22/kill</id>
    <content type="html"><![CDATA[<h2 id="section">前言</h2>

<p>今天在疯狂地提交计算任务，提交了550多个任务，但是在提交的过程之中,难免会出现一些失误，提交了错误的参数或者设置了错误的程序运行条件。同时因为在深圳的机器是和另一个组的同学同时使用机器，所以经常出现的情况是——当她运行程序的时候，我需要停下来先让师姐运行起来我再接着提交任务。原因就是，我的程序都是单核任务为主，而师姐的程序则是计算蛋白质的并行程序。</p>

<p>所以很自然的，最高效的计算资源利用方法就是我等师姐的程序提交成功之后提交，这样的话单核任务可以多样地被分配到各个节点上而不用等节点空闲来运行并行程序。我们可以最充分地利用组里在深圳租用的资源。</p>

<p>所以一个使用中的痛点就是，你不得不因为各种各样的原因停止自己的程序。 </p>

<p>那么问题来——如何在Linux环境中高效地停止某个任务？</p>

<!--more-->

<h2 id="section-1">方法</h2>

<p>其实实现方法也特别简单，因为<code>ps</code>是可以列出所有当前进程的(深圳超算中心提供了类似的命令<code>bjobs</code>)。下面的问题就是如何将<code>ps</code>列出的进程停止掉，很自然地我们发现Linux已经提供了<code>kill</code>命令。</p>

<p>所以组合一下，最后脚本如下：</p>

<p>```bash</p>

<h1 id="binsh">!/bin/sh</h1>
<p>psname=’chanel9.1’
ps x | grep $psname | grep -v grep | cut -c 1-5 | xargs kill</p>

<p>```</p>

<p>使用中，需要的修改的部分就是<code>psname</code>，这个字符串代表了你希望停止的进程名字。</p>

<p>这里需要说明我停止的进程都是同一个。所以用这个脚本可以高效地批量停止任务。当然如果你的任务是不同的名字那么其实如果比如进程命名有规律还是可以用<code>grep</code>和<code>sort</code>等组合出来的。</p>

<h2 id="section-2">参考</h2>

<p>我参考了这个网页的方法<a href="http://www.jb51.net/LINUXjishu/43534.html">Linux下批量Kill多个进程的方法</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash脚本的批量作业]]></title>
    <link href="http://iphyer.github.com/blog/2015/06/16/pipe/"/>
    <updated>2015-06-16T17:09:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2015/06/16/pipe</id>
    <content type="html"><![CDATA[<h2 id="section">前言</h2>

<p>其实这个博文很短，就是记录下今天下午写的bash代码。所有完成的工作的目的就是实现对于研究做服务器集群的使用。</p>

<!--more-->

<h2 id="section-1">需求说明</h2>

<ol>
  <li>首先实验室的服务器不同于前面的深圳超算中心代码，深圳超算是可以疯狂提交，因为后台的作业调度系统自动帮助你进行调度。一次一个核的安排。我的任务就是只使用一个核，但是需要同时计算很多任务，比如50个。</li>
  <li>实验室服务器性能比较好，但是一个节点只有15个核，但是当提交多于15个任务的时候就会出现性能的下降。所以我的任务要求就是可以控制总任务量比如50个任务，保持运行任务数目为15个，一个任务结束，另外一个任务自动开启。</li>
  <li>可以后台运行，这样方便我关闭机器，回头再查看任务结果。</li>
</ol>

<h2 id="bash">bash脚本</h2>
<p>网上发现一个非常好的脚本，<a href="http://jerkwin.github.io/2013/12/14/Bash%E8%84%9A%E6%9C%AC%E5%AE%9E%E7%8E%B0%E6%89%B9%E9%87%8F%E4%BD%9C%E4%B8%9A%E5%B9%B6%E8%A1%8C%E5%8C%96/">Bash脚本实现批量作业并行化</a></p>

<p>基本上，整体的代码都是参考的作者的实现只是修改了CMD这个函数部分。</p>

<p>```bash</p>

<h1 id="binsh">!/bin/sh</h1>
<p>Possibility=”step10”
date=”20150602”
prog=”chanel8.3.1”</p>

<p>mkdir ~/run/${date}/${Possibility}</p>

<p>Njob=50    # 作业数目
Nproc=3    # 可同时运行的最大作业数</p>

<p>function CMD {        # 测试命令, 随机等待几秒钟
    mkdir ~/run/${date}/${Possibility}/no$1
    cd ~/run/${date}/${Possibility}/no$1
    cp ~/run/${date}/${prog} .
	./${prog}&gt;record  <br />
}</p>

<p>Pfifo=”/tmp/$$.fifo”   # 以PID为名, 防止创建命名管道时与已有文件重名，从而失败
mkfifo $Pfifo          # 创建命名管道
exec 6&lt;&gt;$Pfifo         # 以读写方式打开命名管道, 文件标识符fd为6
                       # fd可取除0, 1, 2,5外0-9中的任意数字
rm -f $Pfifo           # 删除文件, 也可不删除, 不影响后面操作</p>

<h1 id="fd6nproc">在fd6中放置$Nproc个空行作为令牌</h1>
<p>for((i=1; i&lt;=$Nproc; i++)); do
	echo
done &gt;&amp;6</p>

<p>for((i=1; i&lt;=$Njob; i++)); do  # 依次提交作业
	read -u6                   # 领取令牌, 即从fd6中读取行, 每次一行
                               # 对管道，读一行便少一行，每次只能读取一行
                               # 所有行读取完毕, 执行挂起, 直到管道再次有可读行
                               # 因此实现了进程数量控制
	{                          # 要批量执行的命令放在大括号内, 后台运行
		CMD $i &amp;&amp; {            # 可使用判断子进程成功与否的语句
			echo “Job $i finished”
		} || {
			echo “Job $i error”
		}
		sleep 1     # 暂停1秒，可根据需要适当延长,
                    # 关键点，给系统缓冲时间，达到限制并行进程数量的作用
		echo &gt;&amp;6    # 归还令牌, 即进程结束后，再写入一行，使挂起的循环继续执行
	} &amp;</p>

<p>done</p>

<p>wait                # 等待所有的后台子进程结束
exec 6&gt;&amp;-           # 删除文件标识符</p>

<p>```</p>

<p>然后用这个方式运行，<code>bash test3.sh &gt; log &amp;</code></p>

<p>后面的”&amp;”号一定要加上，这样这个脚本就转入后台运行，可以更加方便。</p>

<p>然后<code>top</code>查看下运行的进程，确保脚本启动成功。</p>

<p><img src="/images/bash/bashpipe.png" alt="top" /></p>
]]></content>
  </entry>
  
</feed>
