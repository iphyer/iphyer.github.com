<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 计算机, | 桑弧蓬矢射四方]]></title>
  <link href="http://iphyer.github.com/blog/categories/计算机-/atom.xml" rel="self"/>
  <link href="http://iphyer.github.com/"/>
  <updated>2018-04-30T19:02:23-05:00</updated>
  <id>http://iphyer.github.com/</id>
  <author>
    <name><![CDATA[iphyer]]></name>
    <email><![CDATA[iphyer@163.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[用矩阵操作快速实现图像识别的准确率判断]]></title>
    <link href="http://iphyer.github.com/blog/2018/04/30/matrix/"/>
    <updated>2018-04-30T16:52:00-05:00</updated>
    <id>http://iphyer.github.com/blog/2018/04/30/matrix</id>
    <content type="html"><![CDATA[<h2 id="section">起因</h2>

<p>今天和同学一切讨论我们在做的项目，其中他特别指出了一段 Python 代码的精妙之处。我当时没能立刻理解，回来仔细思考了多次，终于想明白了这个问题，不由拍案叫绝。所以特地总结下这个问题给出自己的思考。</p>

<h2 id="section-1">背景</h2>

<h3 id="section-2">像素坐标系</h3>

<p>我们都知道，计算机图像是由像素点组成的。简单化的理解，忽律各种格式的区别，就是红色，绿色，蓝色三个通道的二维矩阵组合。一个通道是一个矩阵，这样在屏幕上，同一个像素点，三种颜色的混合就组成了一幅彩色图像。如下图所示</p>

<p><img src="/images/ComputerVision/pixelCoordinate.png" alt=" from cs239n by Fei-Fei Li,Justin Johnson,Serena Yeung" /></p>

<p>人看到的是色彩斑澜的图像，计算机看到的其实是一个填充了数字的矩阵。</p>

<h3 id="bounding-box">Bounding Box</h3>

<p>在图像识别的时候很重要的一个工作是通过 Bounding Box 把图像的大致区域框出来。在这一步并不需要每一个像素都精确区分，而是大致框出物体的范围。如下图所示：</p>

<p><img src="/images/ComputerVision/BoundingBox.png" alt="Bounding Box" /></p>

<p>那么问题来了，怎么表示这个 Bounding Box？</p>

<p>需要画出边框上的每个点吗？ 显然不需要。</p>

<p>那最少需要几个？现在四个顶点时最特殊的，那四个都必须吗？显然也不需要。</p>

<p>最少我们只需要不是共线的两个顶点就行了，也就是互为对角线的顶点都可以。</p>

<p>习惯上我们取左上的点和右下的点（从人的角度看，暂时不考虑像素坐标系的方向问题）。</p>

<h3 id="section-3">图像识别算法</h3>

<p>如上面的 Bounding Box 图所示，其实图像识别算法就是对于任意一个输入的图像，考察是不是准备地预测出了 Bounding Box 的所在位置。当然为了让算法可以知道怎么学习，我们往往会事先通过 Bounding Box 标记出图像的位置，然后训练神经网络去通过学习图像的各种特征预测可能出现的Bounding Box 位置。</p>

<p>简单说，我们先标记一些 Bounding Box 然后我们的算法通过学习训练，最后实现对于一张未知图像的 Bounding Box 的预测。</p>

<h3 id="precision-and-recall">precision(准确率) and recall(召回率)</h3>

<p>这里就会有一个很自然的，我们怎么知道预测的准确还是不准确呢？</p>

<p>通常在机器学习算法中我们使用两个指标来表示算法的性能，precision(准确率) and recall(召回率)。简单说，如果用疾病检测举例，如果在 10000 人的检测样本中 500 个阳性的病人需要预测出来，现在你设计了一个算法，预测了 400 个人是阳性，但是实际上这四百人里面只有 300 人是真的阳性，其中 100 个人是阴性。所以你的准确率就是说，基于你预测的 400 人，有 300 人是对的，所以准备率是 300 / 400 = 0.75。 换句话说准确率就是你预测的所有结果中有多少是对的。</p>

<p>召回率是表示的是你预测的结果中对的部分到底覆盖了多少目标用户，可以看到我们的目标是预测出 500 个阳性病人，但是你预测的 400 人中只有 300 个是对的，所以你的召回率就是 300 / 500 = 0.6。简单说，召回率就是覆盖率，我们希望你在准备预测的时候，能够覆盖的越多的目标人群越好。</p>

<p>极端情况，如果你值预测一个人，同时这个人还是真是阳性，可以看到 准确率是 1 / 1 = 100%， 但是你的召回率只有 1/ 500 = 0.002 非常低。
另外的极端情况就是，你说所有人都是阳性病人，那么召回率就是 1。因为你把所有病人都包括了，你预测对的人是 500，同时你期望的目标人群是500， 500 / 500 = 1。换句话说，通过非常极端严格筛查条件，宁可错误绝不放过，你成功实现了全覆盖。但是你的准确率低得令人发指，只有 500 / 10000 = 0.05。</p>

<p>所以在日常的使用中，我们往往是需要综合两个指标的。比较自然的指标有 F1 分数等。有兴趣的读者可以自行研究。</p>

<h2 id="section-4">问题</h2>

<h3 id="section-5">问题的提出</h3>

<p>我们集中到今天讨论的问题上，</p>

<blockquote>
  <p>假设对于某个图像，我的算法提出了自己预测的 N 个 Bounding Box，同时知道该图像的 M 个正确的 Bounding Box， 如何准备快速的计算 precision(准确率) and recall(召回率)？</p>
</blockquote>

<p>下面我给出问题的设立代码和画图代码帮助大家理解这个问题：</p>

<p>```python</p>

<p>import numpy as np</p>

<h1 id="create-array-data">create array data</h1>

<p>predict = np.array([[1,2,2,1],
                   [4.5,2.5,2,1],
                   [6,6,8,4]], np.double)</p>

<p>truth = np.array([[1,4,3,3],
                   [5,2,8,1]], np.double)</p>

<h1 id="below-is-to-show-the-layout-of-the-problem">Below is to show the layout of the problem</h1>
<p># red represents truth
# blue represents prediction</p>

<p>import matplotlib.pyplot as plt
import matplotlib.patches as patches
fig = plt.figure()
ax = fig.add_subplot(111, aspect=’equal’)
recList = list()</p>

<h1 id="adding-blue-rectangle-from-predict">Adding blue rectangle from predict</h1>
<p>for rect in predict:
    recList.append(
        patches.Rectangle(
            (rect[0], rect[3]),
             np.abs(rect[2] - rect[0]),
             np.abs(rect[3] - rect[1]),
             fill=False,
             edgecolor = “blue”
        )
    )</p>

<h1 id="adding-red-rectangle-for-truth">Adding red rectangle for truth</h1>
<p>for rect in truth:
    recList.append(
        patches.Rectangle(
            (rect[0], rect[3]),
             np.abs(rect[2] - rect[0]),
             np.abs(rect[3] - rect[1]),
             fill=False,
             edgecolor = “red”
        )
    )</p>

<h1 id="plot-the-graph">plot the graph</h1>
<p>for p in recList:
    ax.add_patch(p)</p>

<p>plt.plot()
plt.show()
fig.savefig(‘rect.png’, dpi=90, bbox_inches=’tight’)</p>

<p>```</p>

<p>具体的图像如下；</p>

<p><img src="/images/ComputerVision/rect.png" alt="Bounding Box Layout" /></p>

<p>同时我们做一个简化，<strong>只考虑每个矩阵中心是不是在可以接受的误差范围内重合</strong>。相当于我们暂时只考虑未知不考虑大小。因为大小往往还会做后续的精细调节。很多算法只是粗略地估计大小到了需要的时候，在进一步的细化。</p>

<p>计算中心可以使用如下的函数</p>

<p>```python</p>

<p>’’’
Calculate the center point of bounding box
‘’’
def bbox2centroid(bboxes):
    return np.column_stack(((bboxes[:, 0] + bboxes[:, 2])/2, (bboxes[:, 1] + bboxes[:, 3])/2))</p>

<p>```</p>

<h3 id="section-6">问题的思路</h3>

<p>一个简单的思路就是挨个比较。这样的话你的算法需要写大量的循环非常费力。</p>

<p>所以，在实际的工作中，我们大量使用矩阵操作，避免循环。因为矩阵操作往往可以避免循环，同时如果你能够使用 GPU，通常图像识别都会在 GPU 上运行，举证操作本身是优化和特别适合的。这可以提高速度。</p>

<p>但是怎么做操作？</p>

<p>可以看到我特地给出了，预测 Bounding Box 数量和真实 Bounding Box 数量不一致的情况，所以这个时候如果不小心非常容易出现矩阵的维度不匹配的情况那就毁掉了所有的计算。</p>

<p>所以我们可以用上面的例子来帮助思考，首先求中心的坐标，这样，原来的 $ N \times 4 $ 矩阵和 $ M \times 4 $ 矩阵就变成了
$ N \times 2 $ 矩阵和 $ M \times 2 $ 矩阵。</p>

<h4 id="numpy--numpynewaxis">Numpy 的 <code>numpy.newaxis</code></h4>

<h3 id="section-7">问题的解决代码</h3>

<p>这里我直接先给出代码。</p>

<p>```python</p>

<p>’’’
Calculating P and R function
‘’’
def compute_score_detail_by_centroid(pred_bbox, gt_bbox, tolerence=(2, 2)):
    pred_c = bbox2centroid(pred_bbox)
    gt_c = bbox2centroid(gt_bbox)
    diffs = abs(pred_c[:, None] - gt_c)
    x1, x2 = np.nonzero((diffs &lt; tolerence).all(2))
    return np.unique(x2), np.unique(x1)
```</p>
]]></content>
  </entry>
  
</feed>
