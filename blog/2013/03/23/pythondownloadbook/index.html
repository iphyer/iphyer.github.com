
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>PythonDownloadBook  | 桑弧蓬矢射四方</title>

<meta name="author" content="iphyer"> 

<meta name="description" content="下载书籍 好久没有更新这个技术blog了，今天终于可以写一个新的内容了。
主要是关于一本书的《西藏生死书》，这本书总是在图书馆借不到，所以自己写程序去下载。 程序思路 其实很简单就是读入网页，然后用BeautifulSoup解析网页内容，本来以为会有好多内容的，结果最后发现用一个语法就可以解决了 &hellip;"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="桑弧蓬矢射四方" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	<!--- MathJax Configuration -->
<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://drz.ac/javascripts/MathJaxLocal.js">
</script>

</head>



<body>
	<header id="header" class="inner"><h1><a href="/">桑弧蓬矢射四方</a></h1>
<h4></h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/about">About</a></li>
	<li><a href="/portfolio">Portfolio</a></li>
	<li><a href="/archives">Archive</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/about">About</a></li>
	<li><a href="/portfolio">Portfolio</a></li>
	<li><a href="/archives">Archive</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:iphyer.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">PythonDownloadBook</h2>
	<div class="entry-content"><h1 id="section">下载书籍</h1>

<p>好久没有更新这个技术blog了，今天终于可以写一个新的内容了。
主要是关于一本书的《西藏生死书》，这本书总是在图书馆借不到，所以自己写程序去下载。</p>

<h1 id="section-1">程序思路</h1>

<p>其实很简单就是读入网页，然后用BeautifulSoup解析网页内容，本来以为会有好多内容的，结果最后发现用一个语法就可以解决了。
主要是这个网页比较干净，几乎没有什么其他的东西。
当然程序的实现还是需要很多的其他环境的，比如这个网站是gbn2312编码的，但是内中还夹杂了其他的编码，所以python一开始老是报错。
最后借助了很多的其他手段解决了。比如Linux环境。</p>

<!--more-->

<h1 id="section-2">程序</h1>

<pre><code>
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 21 15:38:23 2013

@author: Aimzest
"""
import urllib2
from bs4 import BeautifulSoup


fh=open('content.txt','a+')
#参数设定
urllinkmain="http://www.oklink.net/00/0325/sss/"
urllinkadd=".htm"

#下载程序
fh.write(u"西藏生死书 \n")

for n in range(1,27):
    temp=str(n)
    temp=temp.zfill(3)
    bookfilelink=urllinkmain+temp+urllinkadd
    #解析网页
    request = urllib2.Request(bookfilelink)
    request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')
    response = urllib2.urlopen(request)
    soup=BeautifulSoup(response,from_encoding="gb18030")
    content=soup.get_text()
    #输出章节标题和内容
    fh.write(content)
    
fh.close()

print  'Done'

</code></pre>

<p>这是最后的程序版本。</p>

<p>当然还要手动去掉那些多出来的东西，主要是</p>

<ul>
  <li>返回上页</li>
  <li>一个css的残留项目。估计是里面有中文所以去不掉</li>
</ul>

<p>就是这个字符串</p>

<pre><code>
#page {position:absolute; z-index:0; left:0px; top:0px}
.swy1 {font: 12pt/16pt "宋体"} 
.swy2 {font: 9pt/12pt "宋体"} 

</code></pre>

<p>我一直没想明白怎么去掉。但是可以手动使用查找替换所以其实也很简单了。</p>

<p>或者下载到本地以后，再读入content重新修改估计都是可以的。</p>

<h1 id="section-3">总结</h1>

<p>主要是三点</p>

<h2 id="section-4">字符串的迭代</h2>

<p>这里我需要产生，001，002，003的字符串。其实很简单的方法就可以了：</p>

<pre><code>for n in range(1,27):
    temp=str(n)
    temp=temp.zfill(3)
</code></pre>

<p>python的zfill真是强大。</p>

<h2 id="urllib">urllib的访问限制</h2>

<p>urllib是尊重roobtxts里面的限制的。所以比较好的方法是加上一个修饰：</p>

<p>比较完整表达是：</p>

<p>urllib2 respects robots.txt. </p>

<p>Many sites block the default User-Agent.</p>

<p>Try adding a new User-Agent, by creating Request objects &amp; using them as arguments for urlopen</p>

<pre><code>  request = urllib2.Request(bookfilelink)
    request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')
    response = urllib2.urlopen(request)
</code></pre>

<h1 id="section-5">很好的解析网页命令</h1>

<p>这个命令绝对实用啊</p>

<pre><code>content=soup.get_text()
</code></pre>

<p>直接就可以得到需要的网页内容了。</p>

<h1 id="stackoverflow">stackoverflow是神迹</h1>

<p>我在写的时候有一个问题，在stackoverflow上提问，结果一下就有5个人回应，真实神迹啊！
比百度知道靠谱多了。</p>

<p>赞！</p>

<h1 id="section-6">效果</h1>

<p>最后的效果如下，导入kindle慢慢欣赏了。</p>

<p><img src="/images/Python/downloadbook/1.png" alt="tu1" /> </p>
</div>


<div class="meta">
	<div class="date">








  


<time datetime="2013-03-23T11:33:00-05:00" pubdate data-updated="true">Mar 23<span>rd</span>, 2013</time></div>
	

<div class="tags">

	<a class='category' href='/blog/categories/python/'>Python</a>

</div>


	
		<span class="comments"><a href="/blog/2013/03/23/pythondownloadbook/#disqus_thread">Comments</a></span>
	
</div></article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
	
	
	
<!---	<a class="addthis_counter addthis_pill_style"></a> --->
	</div>
  <script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid="></script>
</div>



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2017

    iphyer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'iphyersblog';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://iphyer.github.com/blog/2013/03/23/pythondownloadbook/';
        var disqus_url = 'http://iphyer.github.com/blog/2013/03/23/pythondownloadbook/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-33194427-1');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



</body>
</html>
